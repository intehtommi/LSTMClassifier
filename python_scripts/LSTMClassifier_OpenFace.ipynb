{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tround(num, dec=0):\n",
    "    if (np.isnan(num)):\n",
    "        return 0\n",
    "    else:\n",
    "        a = math.floor(float(num))\n",
    "        if (num%1>=0.5):\n",
    "            return(a+1)\n",
    "        else:\n",
    "            return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoredf = pd.read_csv(\"../Time-Table-Annotation.csv\")\n",
    "AU = pd.read_csv(\"../OpenFace_200/A1/AU/002-A-L-AU.csv\")\n",
    "score = scoredf.loc[1:,[\"ID\",\"Class Level\"]]\n",
    "score=score.dropna().values\n",
    "train_index = np.array([1,2])\n",
    "test_index = np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset_create(train_index, test_index, AU, score):\n",
    "    X_train = np.empty([AU.T.shape[0],AU.T.shape[1]])\n",
    "    X_test = np.empty([AU.T.shape[0],AU.T.shape[1]])\n",
    "    count = []\n",
    "    for filenum in train_index:\n",
    "        if (''.join(glob.iglob('../OpenFace_200/**/'+score[filenum][0]+'*-AU.csv', recursive=True))==''):\n",
    "            count.append(filenum)\n",
    "        else:\n",
    "            for filename in glob.iglob('../OpenFace_200/**/'+score[filenum][0]+'*-AU.csv', recursive=True):\n",
    "                AU = pd.read_csv(filename).values\n",
    "                if (X_train.shape[1]>AU.T.shape[1]):\n",
    "                    X_train = X_train[:,0:AU.T.shape[1]] #reduces features to the minimum of all test data. Is this ok?\n",
    "                X_train = np.dstack((X_train, AU.T[:,0:X_train.shape[1]]))\n",
    "    train_index = train_index.tolist()\n",
    "    for i in count:\n",
    "        train_index.remove(i)\n",
    "    count =[]\n",
    "    for filenum in test_index:\n",
    "        if (''.join(glob.iglob('../OpenFace_200/**/'+score[filenum][0]+'*-AU.csv', recursive=True))==''):\n",
    "            count.append(filenum)\n",
    "        else:\n",
    "            for filename in glob.iglob('../OpenFace_200/**/'+score[filenum][0]+'*-AU.csv', recursive=True):\n",
    "                AU = pd.read_csv(filename).values\n",
    "                if (X_test.shape[1]>AU.T.shape[1]):\n",
    "                    X_test = X_test[:,0:AU.T.shape[1]] #reduces features to the minimum of all test data. Is this ok?\n",
    "                    X_train = X_train[:,0:AU.T.shape[1]] #reduces features to the minimum of all test data. Is this ok?\n",
    "                X_test = np.dstack((X_test, AU.T[:,0:X_test.shape[1]]))\n",
    "    test_index = test_index.tolist()\n",
    "    for i in count:\n",
    "        test_index.remove(i)\n",
    "    y_test = np.array([tround(float(score[i][1])) for i in test_index])\n",
    "    y_train = np.array([tround(float(score[i][1])) for i in train_index])\n",
    "    X_train = X_train[:,:,1:]\n",
    "    X_test = X_test[:,:X_train.shape[1],1:]\n",
    "    X_train = X_train.transpose(2,0,1)\n",
    "    #X_train = np.reshape(X_train[:,:,:], [-1, X_train.shape[1]*X_train.shape[-1]])\n",
    "    X_test = X_test.transpose(2,0,1)\n",
    "    #X_test = np.reshape(X_test[:,:,:], [-1, X_test.shape[1]*X_test.shape[-1]])\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapeindices_flat(X_train, X_test):\n",
    "    X_train = np.reshape(X_train, [-1, X_train.shape[1]*X_train.shape[-1]])\n",
    "    X_test = np.reshape(X_test, [-1, X_test.shape[1]*X_test.shape[-1]])\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapeindices_split(data,frames, axis):\n",
    "    splitint = math.floor(data.shape[axis]/frames)\n",
    "    split_indices = [frames*(i+1) for i in range(splitint-1)]\n",
    "    data = data[:,:,:(splitint*5)]\n",
    "    data = np.array_split(data, split_indices, axis=2)\n",
    "    data=np.stack(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VerificationDataset(trainsize, featsize, samplelength, testsize): #This is for debug purposes, generates a similar dataset with label 1-6 and train data 1-6.\n",
    "    x = np.floor(np.arange(trainsize)/(trainsize/6))\n",
    "    c = np.ones((featsize,samplelength))\n",
    "    X_train = x[..., None, None] * c[None, :, :]\n",
    "    y = np.floor(np.arange(testsize)/(testsize/6))\n",
    "    X_test = y[..., None, None] * c[None, :, :]\n",
    "    y_train = x\n",
    "    y_test = y\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, inputDim, hiddenDim, outputDim):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.input_layer = nn.Linear(inputDim, hiddenDim)\n",
    "        self.rnn = nn.LSTM(input_size = hiddenDim,\n",
    "                            hidden_size = hiddenDim,\n",
    "                            batch_first = True)\n",
    "        self.output_layer = nn.Linear(hiddenDim, outputDim)\n",
    "        #self.softmax= nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, inputs, hidden0=None):\n",
    "        #print(inputs.shape)\n",
    "        #inputs = inputs.permute(1,0,2)\n",
    "        #print(inputs.shape)\n",
    "        output = self.input_layer(inputs) #行列サイズ対処\n",
    "        #print(output.shape)\n",
    "        output, (hidden, cell) = self.rnn(output, hidden0) #LSTM層\n",
    "        output = self.output_layer(output[:, -1, :]) #全結合層\n",
    "        #output = self.softmax(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 10, shuffle = True)\n",
    "for train_index, test_index in kf.split(score):\n",
    "    X_train, X_test, y_train, y_test = Dataset_create(train_index, test_index, AU, score)\n",
    "    #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = VerificationDataset(500, 18, 20, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = reshapeindices_split(X_train, 5, 2)\n",
    "X_test = reshapeindices_split(X_test, 5, 2)\n",
    "X_train = X_train.transpose(2,3,0,1)\n",
    "X_test = X_test.transpose(2,3,0,1)\n",
    "tileamount = X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2]*X_train.shape[3],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2]*X_test.shape[3],1)\n",
    "X_train = X_train.transpose(2,3,1,0)\n",
    "X_test = X_test.transpose(2,3,1,0)\n",
    "y_traintensor = np.tile(y_train, tileamount)\n",
    "y_traintensor = np.repeat(y_traintensor[None, :], X_train.shape[2], axis=0)\n",
    "y_testtensor = np.tile(y_test, tileamount)\n",
    "y_testtensor = np.repeat(y_testtensor[None, :], X_train.shape[2], axis=0)\n",
    "X_train=X_train[:,:,:,1:]\n",
    "X_test = X_test[:,:,:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2000) (5, 200)\n"
     ]
    }
   ],
   "source": [
    "print(y_traintensor.shape, y_testtensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = X_train.shape[0] #traning dataのデータ数\n",
    "epochs_num = 100 #traningのepoch回数\n",
    "hidden_size = 50 #LSTMの隠れ層の次元数\n",
    "\n",
    "model = Predictor(X_train.shape[3], hidden_size, 7) #modelの宣言\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() #評価関数の宣言\n",
    "optimizer = Adam(model.parameters(), lr=0.001) #最適化関数の宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss: 1.289, training_accuracy: 0.56600\n",
      "[5]\n",
      "[0]\n",
      "68.0\n",
      "1 loss: 1.289, training_accuracy: 0.56600, test_accuracy: 0.34000\n",
      "2 loss: 0.892, training_accuracy: 0.66550\n",
      "[0]\n",
      "[0]\n",
      "68.0\n",
      "2 loss: 0.892, training_accuracy: 0.66550, test_accuracy: 0.34000\n",
      "3 loss: 0.708, training_accuracy: 0.74900\n",
      "[0]\n",
      "[0]\n",
      "68.0\n",
      "3 loss: 0.708, training_accuracy: 0.74900, test_accuracy: 0.34000\n",
      "4 loss: 0.336, training_accuracy: 0.88550\n",
      "[0]\n",
      "[0]\n",
      "100.0\n",
      "4 loss: 0.336, training_accuracy: 0.88550, test_accuracy: 0.50000\n",
      "5 loss: 0.248, training_accuracy: 0.92100\n",
      "[0]\n",
      "[0]\n",
      "100.0\n",
      "5 loss: 0.248, training_accuracy: 0.92100, test_accuracy: 0.50000\n",
      "6 loss: 0.164, training_accuracy: 0.94450\n",
      "[0]\n",
      "[0]\n",
      "100.0\n",
      "6 loss: 0.164, training_accuracy: 0.94450, test_accuracy: 0.50000\n",
      "7 loss: 0.127, training_accuracy: 0.96050\n",
      "[0]\n",
      "[0]\n",
      "132.0\n",
      "7 loss: 0.127, training_accuracy: 0.96050, test_accuracy: 0.66000\n",
      "8 loss: 0.081, training_accuracy: 0.97500\n",
      "[0]\n",
      "[0]\n",
      "132.0\n",
      "8 loss: 0.081, training_accuracy: 0.97500, test_accuracy: 0.66000\n",
      "9 loss: 0.096, training_accuracy: 0.97150\n",
      "[0]\n",
      "[0]\n",
      "100.0\n",
      "9 loss: 0.096, training_accuracy: 0.97150, test_accuracy: 0.50000\n",
      "10 loss: 0.054, training_accuracy: 0.98550\n",
      "[0]\n",
      "[0]\n",
      "200.0\n",
      "10 loss: 0.054, training_accuracy: 0.98550, test_accuracy: 1.00000\n",
      "11 loss: 0.004, training_accuracy: 1.00000\n",
      "[0]\n",
      "[0]\n",
      "200.0\n",
      "11 loss: 0.004, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "12 loss: 0.002, training_accuracy: 1.00000\n",
      "[0]\n",
      "[0]\n",
      "200.0\n",
      "12 loss: 0.002, training_accuracy: 1.00000, test_accuracy: 1.00000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-fa0f6d7c40d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print(torch.min(label), torch.max(label))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "running_losscount = []\n",
    "training_accuracycount = []\n",
    "for epoch in range(epochs_num):\n",
    "    dataoutput = []\n",
    "    dataanswer = []\n",
    "    running_loss = 0.0\n",
    "    training_accuracy = 0.0\n",
    "    for i in range(training_size): #X_train = (training_size, batch_size, sample_size, feat_size)\n",
    "        optimizer.zero_grad()\n",
    "        data = torch.tensor([X_train[i][0]]).float()\n",
    "        label = torch.tensor([y_traintensor[0][i]]).long().T\n",
    "        #print(data)\n",
    "        #print(label)\n",
    "        output = model(data.float())\n",
    "        #print(output.shape)\n",
    "        #print(label.shape)\n",
    "        #print(output)\n",
    "        #print(label)\n",
    "        #print(torch.min(output), torch.max(output))\n",
    "        #print(torch.min(label), torch.max(label))\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        #print(output.shape)\n",
    "        output = torch.argmax(output, dim=1)\n",
    "        #print(\"output \" + str(output.data.shape))\n",
    "        #print(output.data)\n",
    "        #print(\"answer \" + str(label.data.shape))\n",
    "        #print(label.data)\n",
    "        #print(np.sum((np.abs((output.data - label.data).numpy()) < 0.1))/len(output.data))\n",
    "        training_accuracy += np.sum((np.abs((output.data - label.data).numpy()) < 0.1))/len(output.data)\n",
    "        dataoutput.append(int(output.data[0]))\n",
    "        dataanswer.append(int(label.data[0]))\n",
    "        if (((i+1)%10000)==0):\n",
    "            print(str(i+1)+\"epochs has passed. It's working, don't worry.\")\n",
    "    training_accuracy /= training_size\n",
    "    running_loss /= (training_size*len(output.data))\n",
    "    print('%d loss: %.3f, training_accuracy: %.5f' % (epoch + 1, running_loss, training_accuracy))\n",
    "    print(dataoutput[::20000])\n",
    "    print(dataanswer[::20000])\n",
    "    running_losscount.append(running_loss)\n",
    "    training_accuracycount.append(training_accuracy)\n",
    "    test_accuracy = 0.0\n",
    "    test_size = int(y_testtensor.shape[1])\n",
    "    for i in range(test_size):\n",
    "        data, label = torch.tensor([X_test[i][0]]).float(), torch.tensor([y_testtensor[0][i]]).long().T\n",
    "        output = model(data.float(), None)\n",
    "        output = torch.argmax(output, dim=1)\n",
    "        test_accuracy += np.sum(np.abs((output.data - label.data).numpy()) < 0.1)/len(output.data)\n",
    "    \n",
    "    print(test_accuracy)\n",
    "    test_accuracy /= test_size\n",
    "\n",
    "    print('%d loss: %.3f, training_accuracy: %.5f, test_accuracy: %.5f' % (epoch + 1, running_loss, training_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
